{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scout2B1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sbollmannMRI/scout2B1/blob/master/Scout2B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKwJpQtE81Ib",
        "colab_type": "text"
      },
      "source": [
        "# Setup\n",
        "Make sure to select a GPU: Click Runtime -> Change runtime type -> GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1WgY3ZrHEoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime â†’ \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYU4v2Ea2dRG",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Connect google drive\n",
        "Connect our Colab Notebook to Google drive so that you can store the data there. <br>\n",
        "This will create a folder called \"scout2B1\" in your google drive to store the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3byM9xK84xW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "try: \n",
        "  from google.colab import drive\n",
        "  google_drive_dir = '/content/drive/My Drive/scout2B1'\n",
        "  # select where to store the data - a free google account is sufficient to store all data in this example. \n",
        "  data_directory = google_drive_dir\n",
        "  # data_directory = local_scratch_dir\n",
        "  drive.mount('/content/drive')\n",
        "except:\n",
        "  local_scratch_dir = '/content'\n",
        "  data_directory = local_scratch_dir\n",
        "\n",
        "if not os.path.isdir(data_directory):\n",
        "    os.mkdir(data_directory)\n",
        "os.chdir(data_directory)\n",
        "\n",
        "\n",
        "# define working directory\n",
        "work_dir = os.path.join(data_directory,'osfstorage')\n",
        "\n",
        "# define checkpoint directory\n",
        "checkpoint_directory = os.path.join(work_dir,'checkpoints')\n",
        "\n",
        "# disable training when set to False\n",
        "training_switch=True\n",
        "# training_switch=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbnfLUgEzgDc",
        "colab_type": "text"
      },
      "source": [
        " # Download Data\n",
        " The data for training our model is stored in OSF (https://osf.io/87hpr/). \n",
        " <br>\n",
        " The data will be downladed from OSF to the Disk allocated by the colab on its virtual machine in the path below:\n",
        " <br>\n",
        "/content/data/osfstorage\n",
        " <br>\n",
        " <br>\n",
        " **Scout**: Containing 28 localizer scans\n",
        " <br>\n",
        " **B1Map**: Containing 28 SA2RAGE B1 map scans of the same group of patients which are already resliced into localizer space and masked. \n",
        " <br>\n",
        " **UnseenData**: Containing one pair of scout and B1 map which is not used during the training process. This data will be used for prediction. \n",
        " <br>\n",
        " <br>\n",
        " The purpose is to use the 28 (scout, B1map) pairs to train a UNet CNN structure so that the network learns how to predict a B1 map from a scout scan. \n",
        " <br>\n",
        " In the next step, we will use the trained network on the unseen data to see if the CNN works on data not used for training. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGoywgJxsS3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Install the client code of Open Sience Framework (OSF)\n",
        " !pip install osfclient"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS8jS4vs1yGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download data from OSF\n",
        "data_exists = False\n",
        "print('testing if ',work_dir, ' exists ...')\n",
        "if os.path.isdir(work_dir):\n",
        "  for element in os.listdir(work_dir):\n",
        "    if ('B1Map') in element:\n",
        "      print('data already exists. To trigger a re-download: Delete ', work_dir)\n",
        "      data_exists = True\n",
        "  \n",
        "if not data_exists:\n",
        "      print('data does not exist yet ...')\n",
        "      print('dowloading data to: ',data_directory)\n",
        "      os.chdir(data_directory)\n",
        "      !osf -p 87hpr clone ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zDxreqK8NUd",
        "colab_type": "text"
      },
      "source": [
        "# Import Packages\n",
        "The packages needed during the project are imported here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pt6mcTsQ6_zg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import os\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib.learn.python.learn import monitors as monitor_lib\n",
        "from tensorflow.python.ops import array_ops\n",
        "import matplotlib.pyplot as plt\n",
        "import nibabel as nib\n",
        "from matplotlib import transforms\n",
        "from scipy import ndimage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtYQU96e7-1u",
        "colab_type": "text"
      },
      "source": [
        "# Function Definitions\n",
        " \n",
        "There are three types of functions defined here. \n",
        "<br>\n",
        "**Main Functions**: \n",
        "<br> \n",
        "1. make_data(): This function crops patches from the data and then converts them to tfrecord files that are used during the training. \n",
        "2. train_model(): This function trains the model using the training parameters that are set in the **TRAIN_FLAGS** dictionary\n",
        "3. predict_model(): This function uses the checkpoints created during the training phase and applies the network to new data.  \n",
        "\n",
        "**Model Architecture**:\n",
        "<br>\n",
        "function *conv_arci* is the function where the architecture of the model is defined using keras and tensorflow\n",
        "\n",
        "**Utility functions**: \n",
        "<br> \n",
        "These functions do a particular job and help the main functions with their tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNPcGtnz5cpb",
        "colab_type": "text"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1zPbnf0P_t6",
        "colab_type": "text"
      },
      "source": [
        "### Function: convert_to\n",
        "This functions converts the input data, which is stored as a numpy array to a TFRecords file that can be read by tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYP7PcWgBauk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _int64_feature(value):\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def _bytes_feature(value):\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def convert_to(input_data, target_data, state, names, tfpath):\n",
        "    \"\"\"    \n",
        "    :param input_data:\n",
        "    :param target_data:\n",
        "    :param state: could be 'training' 'evaluation' etc.\n",
        "    :param names: the name for the file. Is concatenated with the 'state'\n",
        "    :return: A TFRecord-file\n",
        "    \"\"\"\n",
        "    num_examples = input_data.shape[0]\n",
        "\n",
        "    rows = input_data.shape[1]\n",
        "    cols = input_data.shape[2]\n",
        "    depth = 1  # gray-scale image has only 1 channel\n",
        "    filename = os.path.join(tfpath, state + names + '.tfrecord')\n",
        "    print('Writing', filename)\n",
        "\n",
        "    if not os.path.exists(os.path.join(tfpath, state)):  # if the path doesnt exist. Make one\n",
        "        os.makedirs(os.path.join(tfpath, state))\n",
        "\n",
        "    options = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.GZIP)\n",
        "    writer = tf.python_io.TFRecordWriter(filename, options=options)\n",
        "    for index in range(num_examples):\n",
        "        if index % 50 == 0:\n",
        "          print('written ' + str(index) + ' of ' + str(num_examples) + ' examples')\n",
        "        input_data_string = input_data[index].tostring()\n",
        "        target_data_string = target_data[index].tostring()\n",
        "        example = tf.train.Example(features=tf.train.Features(feature={\n",
        "            'height': _int64_feature(rows),\n",
        "            'width': _int64_feature(cols),\n",
        "            'depth': _int64_feature(depth),\n",
        "            'target_data_img': _bytes_feature(target_data_string),\n",
        "            'input_data_img': _bytes_feature(input_data_string)}))\n",
        "        writer.write(example.SerializeToString())\n",
        "    print('success. Wrote ', filename)\n",
        "    writer.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "robhEenFQEca",
        "colab_type": "text"
      },
      "source": [
        "### Function: cut_one_example\n",
        "This function creates patches with predefined size from the input images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGNrKXtH7su8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cut_one_example(p_dim, i, data_target, data_input):\n",
        "    \"\"\"   \n",
        "    :param p_dim:\n",
        "    :return: one example of simulation data\n",
        "    \"\"\"\n",
        "    np.random.seed()  # re-seed - important when running in parallel-mode.\n",
        "\n",
        "    if len(data_target.shape) == 4:\n",
        "        brainX, brainY, brainZ, t = data_target.shape\n",
        "\n",
        "    if len(data_target.shape) == 3:\n",
        "        brainX, brainY, brainZ = data_target.shape\n",
        "\n",
        "    randomX = np.random.randint(0, brainX - p_dim)\n",
        "    randomY = np.random.randint(0, brainY - p_dim)\n",
        "    randomZ = np.random.randint(0, brainZ - p_dim)\n",
        "\n",
        "    data_target_patch = data_target[randomX:randomX + p_dim, randomY:randomY + p_dim, randomZ:randomZ + p_dim]\n",
        "    data_input_patch = data_input[randomX:randomX + p_dim, randomY:randomY + p_dim, randomZ:randomZ + p_dim]\n",
        "    \n",
        "    return data_target_patch, data_input_patch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rMtuOn6Oz_i",
        "colab_type": "text"
      },
      "source": [
        "### Function: generate_file_list\n",
        "This function generates a list of the filenames and the paths in 'filepath'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8QiPOyPO0Jt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_file_list(file_path, p_shape):\n",
        "    \"\"\"\n",
        "    :param file_path: the path to the folder where the files of interest resides\n",
        "    :param p_shape:\n",
        "    :return: a list where the filenames and filepaths have been joined\n",
        "    \"\"\"\n",
        "    filenames = os.listdir(file_path)\n",
        "\n",
        "    for index, item in enumerate(filenames):\n",
        "        if item.__contains__('size' + str(p_shape[0])):\n",
        "            filenames[index] = file_path + item\n",
        "        else:\n",
        "            raise FileNotFoundError('you have files in the folder that does not match the shapes')\n",
        "\n",
        "    return filenames\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Tjl3yb7Pksp",
        "colab_type": "text"
      },
      "source": [
        "### Function: data_input_fn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr63zmN7Pk1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_input_fn(filenames, p_shape, batch=None, nepochs=None, shuffle=True):\n",
        "    def _parser(record):\n",
        "        features = {\n",
        "            'input_data_img': tf.FixedLenFeature([], tf.string, default_value=\"\"),\n",
        "            'target_data_img': tf.FixedLenFeature([], tf.string, default_value=\"\")\n",
        "        }\n",
        "        parsed_record = tf.parse_single_example(record, features)\n",
        "        forward_image = tf.decode_raw(parsed_record['input_data_img'], tf.float32)\n",
        "        forward_image = tf.reshape(forward_image, [p_shape[0], p_shape[1], p_shape[2], 1])\n",
        "\n",
        "        target_data = tf.decode_raw(parsed_record['target_data_img'], tf.float32)\n",
        "        target_data = tf.reshape(target_data, [p_shape[0], p_shape[1], p_shape[2], 1])\n",
        "\n",
        "        return {\"x\": forward_image}, target_data\n",
        "\n",
        "    def _input_fn():\n",
        "\n",
        "        dataset = tf.data.TFRecordDataset(filenames, compression_type='GZIP').map(_parser)\n",
        "        if shuffle:\n",
        "            dataset = dataset.shuffle(buffer_size=1000)\n",
        "        dataset = dataset.repeat(nepochs)\n",
        "        dataset = dataset.batch(batch)\n",
        "\n",
        "        iterator = dataset.make_one_shot_iterator()\n",
        "        features, labels = iterator.get_next()\n",
        "\n",
        "        return features, labels\n",
        "\n",
        "    return _input_fn\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "074yjREz6Cb0",
        "colab_type": "text"
      },
      "source": [
        "## Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2uwX_laQhOe",
        "colab_type": "text"
      },
      "source": [
        "### Function: conv_arci\n",
        "This function creates a model with UNet architcture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK-y6hugQhYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_arci(features, labels, mode, params):\n",
        "  \n",
        "  print(params['type_arci'] + ' has been chosen')\n",
        "\n",
        "  xdim, ydim, zdim = params['shape']\n",
        "  filter_scale = params['filter_downscale_factor']\n",
        "  dropout_rate = params['dropout_rate']\n",
        "  input_shape = array_ops.shape(features[\"x\"])\n",
        "       \n",
        "  if params['type_arci'] == 'UnetResidual1x1':\n",
        "    conv1 = tf.keras.layers.Conv3D(int(64 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                       activation='relu',\n",
        "                                       padding='same', name='conv1', kernel_initializer='he_normal')(features[\"x\"])\n",
        "    drop1 = tf.layers.dropout(inputs=conv1, rate=dropout_rate, training=mode == tf.estimator.ModeKeys.TRAIN,\n",
        "                              noise_shape=(input_shape[0], 1, 1, 1, input_shape[4]))\n",
        "    conv1_1 = tf.keras.layers.Conv3D(int(64 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                      activation='relu',\n",
        "                                      padding='same', name='conv2', kernel_initializer='he_normal')(drop1)\n",
        "    drop2 = tf.layers.dropout(inputs=conv1_1, rate=dropout_rate, training=mode == tf.estimator.ModeKeys.TRAIN,\n",
        "                              noise_shape=(input_shape[0], 1, 1, 1, input_shape[4]))\n",
        "    pool1 = tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2), name='pool1')(drop2)\n",
        "\n",
        "    conv2 = tf.keras.layers.Conv3D(int(128 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                    activation='relu',\n",
        "                                    padding='same', name='conv3', kernel_initializer='he_normal')(pool1)\n",
        "    drop3 = tf.layers.dropout(inputs=conv2, rate=dropout_rate, training=mode == tf.estimator.ModeKeys.TRAIN,\n",
        "                              noise_shape=(input_shape[0], 1, 1, 1, input_shape[4]))\n",
        "    conv2_1 = tf.keras.layers.Conv3D(int(128 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                      activation='relu',\n",
        "                                      padding='same', name='conv4', kernel_initializer='he_normal')(drop3)\n",
        "    drop4 = tf.layers.dropout(inputs=conv2_1, rate=dropout_rate, training=mode == tf.estimator.ModeKeys.TRAIN,\n",
        "                              noise_shape=(input_shape[0], 1, 1, 1, input_shape[4]))\n",
        "    pool2 = tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2), name='pool2')(drop4)\n",
        "\n",
        "    conv3 = tf.keras.layers.Conv3D(int(256 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                    activation='relu',\n",
        "                                    padding='same', name='conv5', kernel_initializer='he_normal')(pool2)\n",
        "    drop5 = tf.layers.dropout(inputs=conv3, rate=dropout_rate, training=mode == tf.estimator.ModeKeys.TRAIN,\n",
        "                              noise_shape=(input_shape[0], 1, 1, 1, input_shape[4]))\n",
        "    conv3_1 = tf.keras.layers.Conv3D(int(256 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                      activation='relu',\n",
        "                                      padding='same', name='conv6', kernel_initializer='he_normal')(drop5)\n",
        "    drop6 = tf.layers.dropout(inputs=conv3_1, rate=dropout_rate, training=mode == tf.estimator.ModeKeys.TRAIN,\n",
        "                              noise_shape=(input_shape[0], 1, 1, 1, input_shape[4]))\n",
        "    pool3 = tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2), name='pool3')(drop6)\n",
        "\n",
        "    conv4 = tf.keras.layers.Conv3D(int(512 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                    activation='relu',\n",
        "                                    padding='same', name='conv7', kernel_initializer='he_normal')(pool3)\n",
        "    drop7 = tf.layers.dropout(inputs=conv4, rate=dropout_rate, training=mode == tf.estimator.ModeKeys.TRAIN,\n",
        "                              noise_shape=(input_shape[0], 1, 1, 1, input_shape[4]))\n",
        "    conv4_1 = tf.keras.layers.Conv3D(int(512 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                      activation='relu',\n",
        "                                      padding='same', name='conv8', kernel_initializer='he_normal')(drop7)\n",
        "    drop8 = tf.layers.dropout(inputs=conv4_1, rate=dropout_rate, training=mode == tf.estimator.ModeKeys.TRAIN,\n",
        "                              noise_shape=(input_shape[0], 1, 1, 1, input_shape[4]))\n",
        "    pool4 = tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2), name='pool4')(drop8)\n",
        "\n",
        "    conv5 = tf.keras.layers.Conv3D(int(1024 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                    activation='relu',\n",
        "                                    padding='same', name='conv9', kernel_initializer='he_normal')(pool4)\n",
        "    drop9 = tf.layers.dropout(inputs=conv5, rate=dropout_rate, training=mode == tf.estimator.ModeKeys.TRAIN,\n",
        "                              noise_shape=(input_shape[0], 1, 1, 1, input_shape[4]))\n",
        "    conv5_1 = tf.keras.layers.Conv3D(int(1024 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                      activation='relu',\n",
        "                                      padding='same', name='conv10', kernel_initializer='he_normal')(drop9)\n",
        "    drop10 = tf.layers.dropout(inputs=conv5_1, rate=dropout_rate, training=mode == tf.estimator.ModeKeys.TRAIN,\n",
        "                                noise_shape=(input_shape[0], 1, 1, 1, input_shape[4]))\n",
        "\n",
        "    up6 = tf.concat(\n",
        "        [tf.keras.layers.Conv3DTranspose(int(512 / filter_scale), (2, 2, 2), strides=(2, 2, 2), padding='same',\n",
        "                                          activation='relu', name='up_conv1', kernel_initializer='he_normal')(\n",
        "            drop10), conv4_1],\n",
        "        axis=-1)\n",
        "    conv6 = tf.keras.layers.Conv3D(int(512 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                    activation='relu',\n",
        "                                    padding='same', name='conv11', kernel_initializer='he_normal')(up6)\n",
        "    conv6 = tf.keras.layers.Conv3D(int(512 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                    activation='relu',\n",
        "                                    padding='same', name='conv12', kernel_initializer='he_normal')(conv6)\n",
        "\n",
        "    up7 = tf.concat(\n",
        "        [tf.keras.layers.Conv3DTranspose(int(256 / filter_scale), (2, 2, 2), strides=(2, 2, 2), padding='same',\n",
        "                                          activation='relu', name='up_conv2', kernel_initializer='he_normal')(\n",
        "            conv6), conv3_1], axis=-1)\n",
        "    conv7 = tf.keras.layers.Conv3D(int(256 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                    activation='relu',\n",
        "                                    padding='same', name='conv13', kernel_initializer='he_normal')(up7)\n",
        "    conv7 = tf.keras.layers.Conv3D(int(256 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                    activation='relu',\n",
        "                                    padding='same', name='conv14', kernel_initializer='he_normal')(conv7)\n",
        "\n",
        "    up8 = tf.concat(\n",
        "        [tf.keras.layers.Conv3DTranspose(int(128 / filter_scale), (2, 2, 2), strides=(2, 2, 2), padding='same',\n",
        "                                          activation='relu', name='up_conv3', kernel_initializer='he_normal')(\n",
        "            conv7), conv2_1], axis=-1)\n",
        "    conv8 = tf.keras.layers.Conv3D(int(128 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                    activation='relu',\n",
        "                                    padding='same', name='conv15', kernel_initializer='he_normal')(up8)\n",
        "    conv8 = tf.keras.layers.Conv3D(int(128 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                    activation='relu',\n",
        "                                    padding='same', name='conv16', kernel_initializer='he_normal')(conv8)\n",
        "\n",
        "    up9 = tf.concat(\n",
        "        [tf.keras.layers.Conv3DTranspose(int(64 / filter_scale), (2, 2, 2), strides=(2, 2, 2), padding='same',\n",
        "                                          activation='relu', name='up_conv4', kernel_initializer='he_normal')(\n",
        "            conv8), conv1_1], axis=-1)\n",
        "    conv9 = tf.keras.layers.Conv3D(int(64 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                    activation='relu',\n",
        "                                    padding='same', name='conv17', kernel_initializer='he_normal')(up9)\n",
        "    conv9 = tf.keras.layers.Conv3D(int(64 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                    activation='relu',\n",
        "                                    padding='same', name='conv18', kernel_initializer='he_normal')(conv9)\n",
        "\n",
        "    adaptation_layer_1 = tf.keras.layers.Conv3D(kernel_size=1, filters=128, strides=(1, 1, 1), name='output_layer',\n",
        "                                          kernel_initializer='he_normal', activation=None)(conv9)\n",
        "\n",
        "    adaptation_layer_2 = tf.keras.layers.Conv3D(kernel_size=1, filters=64, strides=(1, 1, 1), name='output_layer',\n",
        "                                          kernel_initializer='he_normal', activation=None)(adaptation_layer_1)\n",
        "\n",
        "    output_layer = tf.keras.layers.Conv3D(kernel_size=1, filters=1, strides=(1, 1, 1), name='output_layer',\n",
        "                                          kernel_initializer='he_normal', activation=None)(adaptation_layer_2 )\n",
        "\n",
        "    output_layer = tf.add(output_layer, features['x'])\n",
        "    \n",
        "  \n",
        "  if params['type_arci'] == 'UnetResidual1x1SimplerConvPool':\n",
        "      conv1_down = tf.keras.layers.Conv3D(int(64 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                      activation='relu',\n",
        "                                      padding='same', name='conv1_down', kernel_initializer='he_normal')(features[\"x\"])\n",
        "\n",
        "      pool1 = tf.keras.layers.Conv3D(int(64 / filter_scale), kernel_size=(3, 3, 3), strides=(2, 2, 2),\n",
        "                                        activation='relu',\n",
        "                                        padding='same', name='pool1', kernel_initializer='he_normal')(conv1_down)\n",
        "\n",
        "      conv2_down = tf.keras.layers.Conv3D(int(128 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                      activation='relu',\n",
        "                                      padding='same', name='conv2_down', kernel_initializer='he_normal')(pool1)\n",
        "\n",
        "\n",
        "      pool2 = tf.keras.layers.Conv3D(int(64 / filter_scale), kernel_size=(3, 3, 3), strides=(2, 2, 2),\n",
        "                                        activation='relu',\n",
        "                                        padding='same', name='pool2', kernel_initializer='he_normal')(conv2_down)\n",
        "\n",
        "      conv3_down = tf.keras.layers.Conv3D(int(256 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                      activation='relu',\n",
        "                                      padding='same', name='conv3_down', kernel_initializer='he_normal')(pool2)\n",
        "\n",
        "      pool3 = tf.keras.layers.Conv3D(int(64 / filter_scale), kernel_size=(3, 3, 3), strides=(2, 2, 2),\n",
        "                                        activation='relu',\n",
        "                                        padding='same', name='pool3', kernel_initializer='he_normal')(conv3_down)\n",
        "      \n",
        "      conv3_up = tf.keras.layers.Conv3D(int(512 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                      activation='relu',\n",
        "                                      padding='same', name='conv3_up', kernel_initializer='he_normal')(pool3)\n",
        "\n",
        "      up3 = tf.concat(\n",
        "          [tf.keras.layers.Conv3DTranspose(int(256 / filter_scale), (2, 2, 2), strides=(2, 2, 2), padding='same',\n",
        "                                            activation='relu', name='up3', kernel_initializer='he_normal')(\n",
        "              conv3_up), conv3_down], axis=-1)\n",
        "      conv2_up = tf.keras.layers.Conv3D(int(256 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                      activation='relu',\n",
        "                                      padding='same', name='conv2_up', kernel_initializer='he_normal')(up3)\n",
        "\n",
        "      up2 = tf.concat(\n",
        "          [tf.keras.layers.Conv3DTranspose(int(128 / filter_scale), (2, 2, 2), strides=(2, 2, 2), padding='same',\n",
        "                                            activation='relu', name='up_conv3', kernel_initializer='he_normal')(\n",
        "              conv2_up), conv2_down], axis=-1)\n",
        "      conv1_up = tf.keras.layers.Conv3D(int(128 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                      activation='relu',\n",
        "                                      padding='same', name='conv1_up', kernel_initializer='he_normal')(up2)\n",
        "      \n",
        "      \n",
        "      up1 = tf.concat(\n",
        "          [tf.keras.layers.Conv3DTranspose(int(64 / filter_scale), (2, 2, 2), strides=(2, 2, 2), padding='same',\n",
        "                                            activation='relu', name='up_conv4_down', kernel_initializer='he_normal')(\n",
        "              conv1_up), conv1_down], axis=-1)\n",
        "      conv0_up = tf.keras.layers.Conv3D(int(64 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                      activation='relu',\n",
        "                                      padding='same', name='conv0_up', kernel_initializer='he_normal')(up1)\n",
        "      \n",
        "\n",
        "      adaptation_layer_1 = tf.keras.layers.Conv3D(kernel_size=1, filters=128, strides=(1, 1, 1), name='output_layer',\n",
        "                                            kernel_initializer='he_normal', activation=None)(conv0_up)\n",
        "\n",
        "      adaptation_layer_2 = tf.keras.layers.Conv3D(kernel_size=1, filters=64, strides=(1, 1, 1), name='output_layer',\n",
        "                                            kernel_initializer='he_normal', activation=None)(adaptation_layer_1)\n",
        "\n",
        "      output_layer = tf.keras.layers.Conv3D(kernel_size=1, filters=1, strides=(1, 1, 1), name='output_layer',\n",
        "                                            kernel_initializer='he_normal', activation=None)(adaptation_layer_2 )\n",
        "\n",
        "      output_layer = tf.add(output_layer, features['x'])\n",
        "  \n",
        "  if params['type_arci'] == 'UnetResidualSimplerConvPool':\n",
        "      conv1_down = tf.keras.layers.Conv3D(int(64 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                      activation='relu',\n",
        "                                      padding='same', name='conv1_down', kernel_initializer='he_normal')(features[\"x\"])\n",
        "\n",
        "      pool1 = tf.keras.layers.Conv3D(int(64 / filter_scale), kernel_size=(3, 3, 3), strides=(2, 2, 2),\n",
        "                                        activation='relu',\n",
        "                                        padding='same', name='pool1', kernel_initializer='he_normal')(conv1_down)\n",
        "\n",
        "      conv2_down = tf.keras.layers.Conv3D(int(128 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                      activation='relu',\n",
        "                                      padding='same', name='conv2_down', kernel_initializer='he_normal')(pool1)\n",
        "\n",
        "\n",
        "      pool2 = tf.keras.layers.Conv3D(int(64 / filter_scale), kernel_size=(3, 3, 3), strides=(2, 2, 2),\n",
        "                                        activation='relu',\n",
        "                                        padding='same', name='pool2', kernel_initializer='he_normal')(conv2_down)\n",
        "\n",
        "      conv3_down = tf.keras.layers.Conv3D(int(256 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                      activation='relu',\n",
        "                                      padding='same', name='conv3_down', kernel_initializer='he_normal')(pool2)\n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "      pool3 = tf.keras.layers.Conv3D(int(64 / filter_scale), kernel_size=(3, 3, 3), strides=(2, 2, 2),\n",
        "                                        activation='relu',\n",
        "                                        padding='same', name='pool3', kernel_initializer='he_normal')(conv3_down)\n",
        "      \n",
        "      conv3_up = tf.keras.layers.Conv3D(int(512 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                      activation='relu',\n",
        "                                      padding='same', name='conv3_up', kernel_initializer='he_normal')(pool3)\n",
        "      \n",
        "      \n",
        "    \n",
        "\n",
        "\n",
        "      up3 = tf.concat(\n",
        "          [tf.keras.layers.Conv3DTranspose(int(256 / filter_scale), (2, 2, 2), strides=(2, 2, 2), padding='same',\n",
        "                                            activation='relu', name='up3', kernel_initializer='he_normal')(\n",
        "              conv3_up), conv3_down], axis=-1)\n",
        "      conv2_up = tf.keras.layers.Conv3D(int(256 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                      activation='relu',\n",
        "                                      padding='same', name='conv2_up', kernel_initializer='he_normal')(up3)\n",
        "\n",
        "\n",
        "\n",
        "      up2 = tf.concat(\n",
        "          [tf.keras.layers.Conv3DTranspose(int(128 / filter_scale), (2, 2, 2), strides=(2, 2, 2), padding='same',\n",
        "                                            activation='relu', name='up_conv3', kernel_initializer='he_normal')(\n",
        "              conv2_up), conv2_down], axis=-1)\n",
        "      conv1_up = tf.keras.layers.Conv3D(int(128 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                      activation='relu',\n",
        "                                      padding='same', name='conv1_up', kernel_initializer='he_normal')(up2)\n",
        "      \n",
        "      \n",
        "      up1 = tf.concat(\n",
        "          [tf.keras.layers.Conv3DTranspose(int(64 / filter_scale), (2, 2, 2), strides=(2, 2, 2), padding='same',\n",
        "                                            activation='relu', name='up_conv4_down', kernel_initializer='he_normal')(\n",
        "              conv1_up), conv1_down], axis=-1)\n",
        "      conv0_up = tf.keras.layers.Conv3D(int(4 / filter_scale), kernel_size=(3, 3, 3), strides=(1, 1, 1),\n",
        "                                      activation='relu',\n",
        "                                      padding='same', name='conv0_up', kernel_initializer='he_normal')(up1)\n",
        "      \n",
        "\n",
        "      output_layer = tf.add(conv0_up, features['x'])\n",
        "\n",
        "\n",
        "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "      print('predict')\n",
        "\n",
        "      # What the estimator should do in the prediction mode\n",
        "      predictions = {\n",
        "          \"images\": output_layer\n",
        "      }\n",
        "\n",
        "      return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "\n",
        "  # The loss function\n",
        "  if params['cost'] == 'L1':\n",
        "      cost = tf.losses.absolute_difference(labels=labels, predictions=output_layer)\n",
        "\n",
        "  if params['cost'] == 'L2':\n",
        "      cost = tf.losses.mean_squared_error(labels=labels, predictions=output_layer)\n",
        "\n",
        "  # TENSORBOARD\n",
        "  # scalars:\n",
        "  tf.summary.scalar('loss L2', tf.losses.mean_squared_error(labels=labels, predictions=output_layer))\n",
        "  tf.summary.scalar('loss L1', tf.losses.absolute_difference(labels=labels, predictions=output_layer))\n",
        "\n",
        "  tf.summary.histogram('input_image', features[\"x\"])\n",
        "  tf.summary.histogram('output_image', output_layer)\n",
        "  tf.summary.histogram('target_data', labels)\n",
        "\n",
        "  # images:\n",
        "  differenceImage = labels[:, :, :, int(zdim / 2)] - output_layer[:, :, :, int(zdim / 2)]\n",
        "  differenceImageSquared = differenceImage * differenceImage\n",
        "  n_outputs = 1  # the number of output images we want to have in tensorboard\n",
        "  tf.summary.image('input', features[\"x\"][:, :, :, int(zdim / 2)], max_outputs=n_outputs)\n",
        "  tf.summary.image('output', output_layer[:, :, :, int(zdim / 2)], max_outputs=n_outputs)\n",
        "  tf.summary.image('target_data', labels[:, :, :, int(zdim / 2)], max_outputs=n_outputs)\n",
        "  tf.summary.image('difference', differenceImage, max_outputs=n_outputs)\n",
        "  tf.summary.image('differenceSquared', differenceImageSquared, max_outputs=n_outputs)\n",
        "\n",
        "  # What the estimator should do when in training mode\n",
        "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      print(\"started training\")\n",
        "      optimizer = tf.train.AdamOptimizer(learning_rate=params['learning_rate'])\n",
        "      train_op = optimizer.minimize(\n",
        "          loss=cost,\n",
        "          global_step=tf.train.get_global_step())\n",
        "      return tf.estimator.EstimatorSpec(mode=mode, loss=cost, train_op=train_op)\n",
        "\n",
        "  # Add evaluation metrics (for EVAL mode)\n",
        "  eval_metric_ops = {\n",
        "      \"RMSE_eval\": tf.metrics.root_mean_squared_error(labels=labels, predictions=output_layer),\n",
        "      \"mean_abs_eval\": tf.metrics.mean_absolute_error(labels=labels, predictions=output_layer)}\n",
        "\n",
        "  return tf.estimator.EstimatorSpec(\n",
        "      mode=mode,\n",
        "      loss=cost,\n",
        "      eval_metric_ops=eval_metric_ops)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPc0otBd52ky",
        "colab_type": "text"
      },
      "source": [
        "## Main Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAH9MuNVy3jf",
        "colab_type": "text"
      },
      "source": [
        "### Function: make_data\n",
        "This function reads the data (scout/B1map) and creates random patches and converts them to TFRecord files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vjKSeqc9L2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_data(FLAGS):\n",
        "  \n",
        "  p_shape = (FLAGS[\"p_dim\"],FLAGS[\"p_dim\"],FLAGS[\"p_dim\"])\n",
        "  m_time = datetime.now().strftime(\"%Y_%m_%d\")\n",
        "  tfpath = FLAGS[\"directory\"] + '/' + FLAGS[\"mode\"] + '_shape' + str(FLAGS[\"p_dim\"]) + '_' + m_time\n",
        "  \n",
        "  for subjectCnt in range(FLAGS[\"start\"], FLAGS[\"end\"] + 1):    \n",
        "    if FLAGS[\"purpose\"] == 'train':\n",
        "      print('Generating data for partition: ' + str(subjectCnt) + '(Training Data)')\n",
        "    if FLAGS[\"purpose\"] == 'eval':\n",
        "      print('Generating data for partition: ' + str(subjectCnt) + '(Evaluation Data)')\n",
        "    inputs = range(1, FLAGS[\"examples_pr_subject\"] + 1)\n",
        "  \n",
        "    if FLAGS[\"mode\"] == 'brainB1' and FLAGS[\"purpose\"] == 'train':\n",
        "\n",
        "        filenameB1 = os.path.join(FLAGS[\"directory\"], r'B1Map/rMaskedB1MapinScout_' + str(subjectCnt) + '.nii')\n",
        "        img = nib.load(filenameB1)\n",
        "        \n",
        "        filenameAA = os.path.join(FLAGS[\"directory\"], 'Scout/Scout_' + str(subjectCnt) + '.nii')\n",
        "        img_fw = nib.load(filenameAA)\n",
        "\n",
        "        # Normalize\n",
        "        data_input = img_fw.get_fdata()\n",
        "        data_input = data_input / FLAGS[\"train_normalization\"]\n",
        "        data = img.get_fdata()\n",
        "        data = data / FLAGS[\"train_normalization\"]\n",
        "\n",
        "        target_data = np.zeros((FLAGS[\"examples_pr_subject\"], FLAGS[\"p_dim\"], FLAGS[\"p_dim\"], FLAGS[\"p_dim\"]))\n",
        "        input_data = np.zeros((FLAGS[\"examples_pr_subject\"], FLAGS[\"p_dim\"], FLAGS[\"p_dim\"], FLAGS[\"p_dim\"]))\n",
        "\n",
        "        for i in inputs:\n",
        "            target_data[i-1, :, :, :], input_data[i-1, :, :, :] = cut_one_example(FLAGS[\"p_dim\"], i, data, data_input)\n",
        "        \n",
        "        target_data = np.array(target_data)\n",
        "\n",
        "    \n",
        "    # -----  For saving the generated train Data as Nifti file\n",
        "    if FLAGS[\"observeData\"] == 'yes' and FLAGS[\"purpose\"] == 'train':\n",
        "        if not os.path.exists(tfpath):\n",
        "            os.makedirs(tfpath)\n",
        "        # Write normalize data to file if observeData = 'yes' (Shah)\n",
        "        # B1 map\n",
        "        data_nii = nib.Nifti1Image(data, np.eye(4))\n",
        "        out_path = os.path.join(tfpath, FLAGS[\"purpose\"])\n",
        "        out_file_name = out_path + str(subjectCnt) + '_temp_full_image.nii'\n",
        "        nib.save(data_nii, out_file_name)\n",
        "        # Scout\n",
        "        data_input_nii = nib.Nifti1Image(data_input, np.eye(4))\n",
        "        out_path = os.path.join(tfpath, FLAGS[\"purpose\"])\n",
        "        out_file_name = out_path + str(subjectCnt) + '_temp_full_image_conv.nii'\n",
        "        nib.save(data_input_nii, out_file_name)\n",
        "\n",
        "    # (For generating eval Data)\n",
        "    if FLAGS[\"purpose\"] == 'eval' and FLAGS[\"mode\"] == 'brainB1':\n",
        "        p_shape = (FLAGS[\"data_shape_x\"], FLAGS[\"data_shape_y\"], FLAGS[\"data_shape_z\"])\n",
        "\n",
        "        img_b1map = nib.load( FLAGS[\"directory\"] + '/' + r'B1Map/rMaskedB1MapinScout_' + str(subjectCnt) + '.nii')\n",
        "        target_data = np.empty((1, FLAGS[\"data_shape_x\"], FLAGS[\"data_shape_y\"], FLAGS[\"data_shape_z\"]))\n",
        "        data = img_b1map.get_fdata() / FLAGS[\"eval_normalization\"]\n",
        "\n",
        "        img_scout = nib.load( FLAGS[\"directory\"] + '/' + 'Scout/Scout_' + str(subjectCnt) + '.nii')\n",
        "        input_data = np.empty((1, FLAGS[\"data_shape_x\"], FLAGS[\"data_shape_y\"], FLAGS[\"data_shape_z\"]))\n",
        "        data_input = img_scout.get_fdata() / FLAGS[\"eval_normalization\"]\n",
        "\n",
        "        target_data[0, :] = data\n",
        "        input_data[0, :] = data_input\n",
        "\n",
        "    \n",
        "    if not os.path.exists(tfpath):\n",
        "        os.makedirs(tfpath)\n",
        "\n",
        "    print('Data generated. Proceeding to write to a tfrecord')\n",
        "    # The file name with all the parameter names\n",
        "    file_name_with_params = FLAGS[\"purpose\"] + str(subjectCnt) + '-size' + str(p_shape[0]) + '-ex' + str(FLAGS[\"examples_pr_subject\"])\n",
        "\n",
        "    # Convert to Examples and write the result to TFRecords.\n",
        "    convert_to(np.float32(input_data), np.float32(target_data), FLAGS[\"purpose\"] + '/', file_name_with_params, tfpath)\n",
        "\n",
        "\n",
        "  print(\"Do we want to export data as nii-image? \" + FLAGS[\"observeData\"])\n",
        "  if FLAGS[\"observeData\"] == 'yes':\n",
        "    print('Converting the data from tfrecords back to image .......')\n",
        "\n",
        "    for subjectCnt in range(FLAGS[\"start\"], FLAGS[\"end\"] + 1):\n",
        "        file_name_with_params = FLAGS[\"purpose\"] + str(subjectCnt) + '-size' + str(p_shape[0]) + '-ex' + str(FLAGS[\"examples_pr_subject\"])\n",
        "\n",
        "        tf_file = os.path.join(tfpath, FLAGS[\"purpose\"], str(file_name_with_params) + '.tfrecord')\n",
        "        options = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.GZIP)\n",
        "        record_iterator = tf.python_io.tf_record_iterator(path=tf_file, options=options)\n",
        "\n",
        "        record_counter = 1\n",
        "        for string_record in record_iterator:\n",
        "            example = tf.train.Example()\n",
        "            example.ParseFromString(string_record)\n",
        "\n",
        "            input_data_string = (example.features.feature['input_data_img']\n",
        "                .bytes_list\n",
        "                .value[0])\n",
        "\n",
        "            target_data_string = (example.features.feature['target_data_img']\n",
        "                .bytes_list\n",
        "                .value[0])\n",
        "\n",
        "            input_data_img_np = np.frombuffer(input_data_string, dtype=np.float32)\n",
        "            input_data_img = input_data_img_np.reshape(p_shape)\n",
        "            target_data_img_np = np.frombuffer(target_data_string, dtype=np.float32)\n",
        "\n",
        "            print(target_data_img_np.shape)\n",
        "            target_data_img = target_data_img_np.reshape(p_shape)\n",
        "            print(target_data_img.shape)\n",
        "\n",
        "            if np.any(np.isinf(input_data_img_np)):\n",
        "                print('infinite values found in forward data after reconstruction')\n",
        "\n",
        "            elif np.any(np.isinf(target_data_img_np)):\n",
        "                print('infinite values found in ground truth after construction')\n",
        "\n",
        "            if np.any(np.isnan(input_data_img_np)):\n",
        "                print('nan values in forward data')\n",
        "\n",
        "            elif np.any(np.isnan(target_data_img_np)):\n",
        "                print('nan values in ground truth data')\n",
        "\n",
        "            # write out to nifti files in tf range\n",
        "            xform = np.eye(4)\n",
        "            target_data_img_nii = nib.Nifti1Image(target_data_img, xform)\n",
        "            out_path = os.path.join(tfpath, FLAGS[\"purpose\"])\n",
        "            out_file_name = out_path + str(file_name_with_params) + '_' + str(record_counter) + '_target_data_tfrange.nii'\n",
        "            nib.save(target_data_img_nii, out_file_name)\n",
        "\n",
        "            input_data_img_nii = nib.Nifti1Image(input_data_img, xform)\n",
        "            out_path = os.path.join(tfpath, FLAGS[\"purpose\"])\n",
        "            out_file_name = out_path + str(file_name_with_params) + '_' + str(record_counter) + '_forward_tfrange.nii'\n",
        "            nib.save(input_data_img_nii, out_file_name)\n",
        "\n",
        "            record_counter = record_counter + 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAcpwFgWJFPA",
        "colab_type": "text"
      },
      "source": [
        "### Function: train_model\n",
        "This function trains the model with the parameters that are set in the TRAIN_FLAGS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hItRiwITJFbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(TRAIN_FLAGS):\n",
        "    # Some of the parameters to tune the model\n",
        "    p_shape_train = int(((TRAIN_FLAGS[\"data\"]).split('_shape')[1]).split('_')[0])\n",
        "    p_shape_evaluate = (TRAIN_FLAGS[\"data_shape_x\"], TRAIN_FLAGS[\"data_shape_y\"], TRAIN_FLAGS[\"data_shape_z\"])\n",
        "    step_save = 1000\n",
        "\n",
        "    print('Detected a shape of ' + str(p_shape_train) + '. Please check if plausible')\n",
        "    p_shape_train = (p_shape_train, p_shape_train, p_shape_train)\n",
        "\n",
        "    # Define where the checkpoints should be saved\n",
        "    m_time = datetime.now().strftime(\"%Y-%m-%d-%H%M\")\n",
        "        \n",
        "    model_directory = m_time + 'arci-' + TRAIN_FLAGS[\"arci\"] + \\\n",
        "                      '-batch' + str(TRAIN_FLAGS[\"batch_size\"]) + \\\n",
        "                      '-lr' + str(TRAIN_FLAGS[\"learning_rate\"]) + \\\n",
        "                      '-fs' + str(TRAIN_FLAGS[\"filter_scale\"]) + \\\n",
        "                      '-cost_' + str(TRAIN_FLAGS[\"cost\"]) + \\\n",
        "                      '-drop_' + str(TRAIN_FLAGS[\"dropout\"])\n",
        "    \n",
        "    model_path = TRAIN_FLAGS[\"checkpoint_directory\"] + model_directory\n",
        "\n",
        "\n",
        "    # params is a dict we give as an input to the architecture\n",
        "    params = {'shape': p_shape_train,\n",
        "              'type_arci': TRAIN_FLAGS[\"arci\"] ,\n",
        "              'filter_downscale_factor': TRAIN_FLAGS[\"filter_scale\"],\n",
        "              'dropout_rate': TRAIN_FLAGS[\"dropout\"],\n",
        "              'cost': TRAIN_FLAGS[\"cost\"],\n",
        "              'model_path': model_path,\n",
        "              'learning_rate': TRAIN_FLAGS[\"learning_rate\"]}\n",
        "\n",
        "    train_data_filename = generate_file_list(file_path=TRAIN_FLAGS[\"data_directory\"]+TRAIN_FLAGS[\"data\"]+'/train/', p_shape=p_shape_train)\n",
        "    eval_data_filename = generate_file_list(file_path=TRAIN_FLAGS[\"data_directory\"]+TRAIN_FLAGS[\"data\"]+'/eval/', p_shape=p_shape_evaluate)\n",
        "\n",
        "    if TRAIN_FLAGS[\"earlyStopping\"] == 'True':\n",
        "        model_directory = model_directory + '-earlyStopping'\n",
        "    else:\n",
        "        model_directory = model_directory + '_ep' + str(TRAIN_FLAGS[\"epochs\"])\n",
        "\n",
        "    model_directory = model_directory + '-' + str(TRAIN_FLAGS[\"data\"])\n",
        "\n",
        "    model_path = TRAIN_FLAGS[\"checkpoint_directory\"] + model_directory\n",
        "\n",
        "    # setup a configuration for the model\n",
        "    config = tf.estimator.RunConfig()\n",
        "    config = config.replace(\n",
        "        model_dir=model_path,\n",
        "        save_checkpoints_steps=step_save,\n",
        "        keep_checkpoint_max=2,\n",
        "        save_summary_steps=step_save/2,\n",
        "    )\n",
        "\n",
        "    # SETUP OF THE MODEL #\n",
        "\n",
        "    # The input function for training\n",
        "    train_input_fn = data_input_fn(train_data_filename, p_shape=p_shape_train, batch=TRAIN_FLAGS[\"batch_size\"],\n",
        "                                           nepochs=TRAIN_FLAGS[\"epochs\"], shuffle=True)\n",
        "\n",
        "    # The input function for evaluation\n",
        "    eval_input_fn = data_input_fn(eval_data_filename, p_shape=p_shape_evaluate, batch=TRAIN_FLAGS[\"batch_size\"], nepochs=1,\n",
        "                                          shuffle=False)\n",
        "\n",
        "    # Construct our classifier using the model defined in qsm_architecture.py\n",
        "    Model = tf.estimator.Estimator(\n",
        "        model_fn=conv_arci,  # the model function\n",
        "        model_dir=model_path,  # the directory of our model\n",
        "        config=config,\n",
        "        params=params)  # takes a dict as input, in here we can define different parameters for the model\n",
        "    \n",
        "    if TRAIN_FLAGS[\"earlyStopping\"] == 'True':\n",
        "        list_of_monitors_and_hooks = [tf.contrib.learn.monitors.ValidationMonitor(\n",
        "            input_fn=eval_input_fn,\n",
        "            every_n_steps=step_save,\n",
        "            early_stopping_metric='loss',\n",
        "            early_stopping_metric_minimize=True,\n",
        "            early_stopping_rounds=5100)]\n",
        "    else:\n",
        "        list_of_monitors_and_hooks = [tf.contrib.learn.monitors.ValidationMonitor(input_fn=eval_input_fn,\n",
        "                                                                                  every_n_steps=step_save,)]\n",
        "\n",
        "    hooks = monitor_lib.replace_monitors_with_hooks(list_of_monitors_and_hooks, Model)\n",
        "    \n",
        "    # TRAIN\n",
        "    Model.train(\n",
        "        input_fn=train_input_fn,  # number of total steps for which the model can train)\n",
        "        hooks=hooks)  # [logging_hook] for later\n",
        "\n",
        "    return model_directory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUUIaY4rfUgK",
        "colab_type": "text"
      },
      "source": [
        "### Function: predict_model\n",
        "This function predicts B1 from a scout image using the trained network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-dol7pPE68q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_model(PREDICT_FLAGS):\n",
        "  # the directory of the trained model.\n",
        "  # (remember to change the 'checkpoint' file in the folder if you\n",
        "  # want to predict from another checkpoint than the last one\n",
        "  model_directory = PREDICT_FLAGS[\"directory\"]\n",
        "  model_name = model_directory.split('checkpoints/')[1]\n",
        "\n",
        "  p_dim = int((model_directory.split('_shape')[1]).split('_ex')[0])\n",
        "  if PREDICT_FLAGS[\"earlyStopping\"] == 'True':\n",
        "    params = {'type_arci': (model_directory.split('arci-')[-1]).split('-')[0],\n",
        "            'filter_downscale_factor': int((model_directory.split('-fs')[-1]).split('-')[0]),\n",
        "            'dropout_rate': float((model_directory.split('-drop_')[-1]).split('-earlyStopping')[0]),\n",
        "            'shape': (p_dim, p_dim, p_dim),\n",
        "            }\n",
        "  else:\n",
        "    params = {'type_arci': (model_directory.split('arci-')[-1]).split('-')[0],\n",
        "            'filter_downscale_factor': int((model_directory.split('-fs')[-1]).split('-')[0]),\n",
        "            'dropout_rate': float((model_directory.split('-drop_')[-1]).split('_ep')[0]),\n",
        "            'shape': (p_dim, p_dim, p_dim),\n",
        "            }\n",
        "            \n",
        "  # setup a configuration for the Model\n",
        "  config = tf.estimator.RunConfig()\n",
        "  config = config.replace(\n",
        "      model_dir=model_directory,\n",
        "      save_checkpoints_steps=500,\n",
        "      keep_checkpoint_max=2,\n",
        "      save_summary_steps=150)\n",
        "\n",
        "  Model = tf.estimator.Estimator(\n",
        "      model_fn=conv_arci,  # the model function\n",
        "      model_dir=model_directory,  # the directory of our model\n",
        "      config=config,\n",
        "      params=params)  # takes a dict as input, in here we can define different parameters for the model\n",
        "\n",
        "  \n",
        "  # print('Predicting on real scan')\n",
        "\n",
        "  path = PREDICT_FLAGS[\"input_path\"]\n",
        "  input_name = PREDICT_FLAGS[\"scout_name\"]\n",
        "\n",
        "  img = nib.load(path + input_name + '.nii')\n",
        "  inputImage = img.get_fdata() / PREDICT_FLAGS[\"train_normalization\"]\n",
        "  p_shape = inputImage.shape\n",
        "\n",
        "  # reshape for prediction\n",
        "  inputImage = np.expand_dims(inputImage, -1)\n",
        "  inputImage = np.expand_dims(inputImage, 0)\n",
        "\n",
        "  predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "      x={'x': np.float32(inputImage)},\n",
        "      num_epochs=1,\n",
        "      shuffle=False,\n",
        "      batch_size=inputImage.shape[0]\n",
        "  )\n",
        "  predict_results = Model.predict(input_fn=predict_input_fn)\n",
        "\n",
        "  for i, p in enumerate(predict_results):\n",
        "    prediction = np.reshape(p['images'], (p_shape[0], p_shape[1], p_shape[2]))\n",
        "\n",
        "  # prediction = prediction[zero_pad:paddedX-zero_pad, zero_pad:paddedY-zero_pad, zero_pad:paddedZ-zero_pad]\n",
        "  prediction = prediction * PREDICT_FLAGS[\"train_normalization\"]\n",
        "\n",
        "  gt_input_name = PREDICT_FLAGS[\"B1_name\"]\n",
        "  img = nib.load(path + gt_input_name + '.nii')\n",
        "  gtImage = img.get_fdata()\n",
        "\n",
        "  predictionErrorAbs = prediction - gtImage\n",
        "  zero_indices = gtImage == 0\n",
        "  gtImage[zero_indices] = 0.000001\n",
        "  predictionErrorPercent = predictionErrorAbs / gtImage * 100\n",
        "\n",
        "  cutOff = 50\n",
        "  super_threshold_indices = predictionErrorPercent > cutOff\n",
        "  supra_threshold_indices = predictionErrorPercent < -cutOff\n",
        "  predictionErrorPercent[super_threshold_indices] = cutOff\n",
        "  predictionErrorPercent[supra_threshold_indices] = -cutOff\n",
        "\n",
        "  # print(\"writing output files ...\")\n",
        "  output_img = nib.Nifti1Image(predictionErrorPercent, img.affine)\n",
        "  out_file_name = PREDICT_FLAGS[\"output_path\"] + input_name + '_rel_error_cutOff' + str(cutOff) + '_' + model_name + '_DeepFLAIR.nii'\n",
        "  nib.save(output_img, out_file_name)\n",
        "\n",
        "  output_img = nib.Nifti1Image(prediction, img.affine)\n",
        "  out_file_name = PREDICT_FLAGS[\"output_path\"] + input_name + '_prediction_' + model_name + '_DeepFLAIR.nii'\n",
        "  nib.save(output_img, out_file_name)\n",
        "  # print(\"done writing files\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-pRRxpE8H5Y",
        "colab_type": "text"
      },
      "source": [
        "# Step 01: Preparing Data for Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDGLLZk6HtMc",
        "colab_type": "text"
      },
      "source": [
        "Since the pre processing step is time-consuming we have  provided the preprocessed data in the osf storage: brainB1_shape32_2020_04_06\n",
        "<br>\n",
        "The name of the folder follows the rule: brainB1_shape_xx_yy where xx is the size of the patches that we cut randomly from the original images and yy is the date when we ran the pre_processing step on the data\n",
        "<br> \n",
        "If you want to run the step you can remove the pre_processed data by: !rm -rf '/content/osfstorage/brainB1_shape32_2020_04_06/' and run Step 01"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S71H72CBQfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check if the pre-processed data already exists\n",
        "os.chdir(work_dir)\n",
        "pre_processed_data_flag = False\n",
        "\n",
        "for element in os.listdir(work_dir):\n",
        "  if ('brainB1') in element:\n",
        "    dataset_name = element\n",
        "    pre_processed_data_flag = True\n",
        "    print(\"The data is already processed and exists in the storage\", dataset_name)\n",
        "\n",
        "if not pre_processed_data_flag:\n",
        "  print(\"The data does not exists in the storage - generating ...\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yM244DUJIKO",
        "colab_type": "text"
      },
      "source": [
        "Set the parameters for pre_processing data:\n",
        "<br>\n",
        "* How many subjects do we want to include in the training data?\n",
        "<br>\n",
        "Example: 26 Subjects ----> start: 1    and     end:26\n",
        "<br>\n",
        "* Do you want to store the patches as nifit files for checking?\n",
        "<br> \n",
        "if yes ---> observeData:'yes'\n",
        "<br>\n",
        "* How many patches do you want to extract from each image?\n",
        "<br> examples_pr_subject = 1000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iduyx7A-mCOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dimension=32\n",
        "normalization_factor=1500\n",
        "examples_per_subject=500\n",
        "if  pre_processed_data_flag is False:  \n",
        "  # Generating Data for Training: \n",
        "  # Specify how many of the subjects are used for training ----> Start:1  End:26 \n",
        "  FLAGS = {'mode':'brainB1', \n",
        "          'examples_pr_subject':examples_per_subject,\n",
        "          'directory':work_dir, \n",
        "          'observeData':'no', \n",
        "          'start':1, \n",
        "          'end':26, \n",
        "          'purpose':'train', \n",
        "          'p_dim':data_dimension, \n",
        "          'eval_normalization':normalization_factor,\n",
        "          'train_normalization':normalization_factor, \n",
        "          'data_shape_x':160, \n",
        "          'data_shape_y':160, \n",
        "          'data_shape_z':128, \n",
        "          'voxel_size':[1, 1, 1]}\n",
        "\n",
        "  # Generating Data for Evaluation: \n",
        "  # Specify how many of the subjects are used for evaluation ----> Start:27  End:28         \n",
        "  make_data(FLAGS)\n",
        "  FLAGS = {'mode':'brainB1', \n",
        "          'examples_pr_subject':examples_per_subject,\n",
        "          'directory':work_dir, \n",
        "          'observeData':'no', \n",
        "          'start':27, \n",
        "          'end':28, \n",
        "          'purpose':'eval', \n",
        "          'p_dim':data_dimension,\n",
        "          'eval_normalization':normalization_factor,\n",
        "          'train_normalization':normalization_factor,\n",
        "          'data_shape_x':160,\n",
        "          'data_shape_y':160,\n",
        "          'data_shape_z':128,\n",
        "          'voxel_size':[1, 1, 1]}\n",
        "  make_data(FLAGS)\n",
        "else:\n",
        "  print('We skip this step. The preprocessed data exists.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9hNZ0gr5pcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Identify generated dataset: \n",
        "for element in os.listdir(work_dir):\n",
        "  if ('brainB1') in element:\n",
        "    dataset_name = element\n",
        "    print(dataset_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im1xVkb3R0Gu",
        "colab_type": "text"
      },
      "source": [
        "# Step 02: Training the model\n",
        "Before running the train_model you have to change the name of the folder which contains the data accordingly ('data' key in the TRAIN_FLAGS dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gouQyX04RxR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "\n",
        "!mkdir '/content/checkpoints'\n",
        "\n",
        "# Google colab provides less memory than our own GPUs, so we cannot train with identical parameters than used in the original manuscript:\n",
        "TRAIN_FLAGS = {'data':dataset_name,\n",
        "               'arci':'UnetResidualSimplerConvPool',\n",
        "               'batch_size':16,\n",
        "               'learning_rate':0.001,\n",
        "               'filter_scale':4,\n",
        "               'cost':'L2',\n",
        "               'dropout':0,\n",
        "               'earlyStopping':'False',\n",
        "               'data_shape_x':160,\n",
        "               'data_shape_y':160,\n",
        "               'data_shape_z':128,\n",
        "               'epochs':40,\n",
        "               'checkpoint_directory':'/content/checkpoints/',\n",
        "               'data_directory':work_dir+'/',\n",
        "               }\n",
        "\n",
        "if training_switch:\n",
        "  model_directory = train_model(TRAIN_FLAGS)\n",
        "\n",
        "  print ('-------------------------------------------')\n",
        "  print ('training done:')\n",
        "  print('model directory: ', model_directory)\n",
        "\n",
        "  shutil.copytree('/content/checkpoints/'+model_directory, os.path.join(checkpoint_directory,model_directory))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOETnPR6xhD1",
        "colab_type": "text"
      },
      "source": [
        "# Step 03: Predict with Model on unseen data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5JAmjgFJCim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def view_slices_3d(image_3d, slice_nbr, vmin, vmax, title='', cmap='gray'):\n",
        "#   print('Matrix size: {}'.format(image_3d.shape))\n",
        "  fig = plt.figure(figsize=(15, 4))\n",
        "  plt.suptitle(title, fontsize=10)\n",
        "\n",
        "  plt.subplot(131)\n",
        "  plt.imshow(np.take(image_3d, slice_nbr, 2), vmin=vmin, vmax=vmax, cmap=cmap)\n",
        "  plt.title('Z');\n",
        "\n",
        "  plt.subplot(132)\n",
        "  image_rot = ndimage.rotate(np.take(image_3d, slice_nbr, 1),90)\n",
        "  plt.imshow(image_rot, vmin=vmin, vmax=vmax, cmap=cmap)\n",
        "  plt.title('Y');\n",
        "\n",
        "  plt.subplot(133)\n",
        "  image_rot = ndimage.rotate(np.take(image_3d, slice_nbr, 0),90)\n",
        "  plt.imshow(image_rot, vmin=vmin, vmax=vmax, cmap=cmap)\n",
        "  plt.title('X');\n",
        "  cbar=plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBQjpWA5ERjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "print(checkpoint_directory)\n",
        "os.chdir(checkpoint_directory)\n",
        "%tensorboard --logdir ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57KuuFlKx-qP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_names = os.listdir(checkpoint_directory)\n",
        "print(\"found these checkpoints:\")\n",
        "for index,checkpoint_name in enumerate(checkpoint_names):\n",
        "  print(index, ': ', checkpoint_name)\n",
        "\n",
        "# pick_index = 0 # model used in paper\n",
        "pick_index = -1 # last model trained\n",
        "\n",
        "checkpoint_name = checkpoint_names[pick_index]\n",
        "\n",
        "print(\"using \", str(pick_index), \": \" + checkpoint_name)\n",
        "\n",
        "model_path = os.path.join(checkpoint_directory,checkpoint_name)\n",
        "print(\"model path:\", model_path)\n",
        "\n",
        "# Predict on Unseen data\n",
        "PREDICT_FLAGS = {'directory':model_path,\n",
        "                 'input_path':work_dir+'/UnseenData/',\n",
        "                 'scout_name':'Scout',\n",
        "                 'B1_name':'maskedReslicedB1',\n",
        "                 'train_normalization':1500,\n",
        "                 'output_path':data_directory+'/',\n",
        "                 'earlyStopping':'False',\n",
        "                 }\n",
        "\n",
        "# Prediction\n",
        "predict_model(PREDICT_FLAGS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmlUgkije3u_",
        "colab_type": "text"
      },
      "source": [
        "# Step 04: Visualise Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7Lr0n9DhFod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# visulize data\n",
        "print(\"Visualizing data predicted using: \" + checkpoint_name)\n",
        "\n",
        "path = PREDICT_FLAGS[\"input_path\"]\n",
        "img = nib.load(path + PREDICT_FLAGS[\"scout_name\"] + '.nii')\n",
        "inputImage = img.get_fdata() / PREDICT_FLAGS[\"train_normalization\"]\n",
        "\n",
        "out_file_name = PREDICT_FLAGS[\"output_path\"] + PREDICT_FLAGS[\"scout_name\"] + '_prediction_' + checkpoint_name + '_DeepFLAIR'\n",
        "img = nib.load(out_file_name + '.nii')\n",
        "predImage = img.get_fdata()\n",
        "\n",
        "img = nib.load(path + PREDICT_FLAGS[\"B1_name\"] + '.nii')\n",
        "gtImage = img.get_fdata()\n",
        "\n",
        "\n",
        "predictionErrorAbs = predImage - gtImage\n",
        "zero_indices = gtImage == 0\n",
        "gtImage[zero_indices] = 0.000001\n",
        "predictionErrorPercent = predictionErrorAbs / gtImage * 100\n",
        "\n",
        "cutOff = 50\n",
        "super_threshold_indices = predictionErrorPercent > cutOff\n",
        "supra_threshold_indices = predictionErrorPercent < -cutOff\n",
        "predictionErrorPercent[super_threshold_indices] = cutOff\n",
        "predictionErrorPercent[supra_threshold_indices] = -cutOff\n",
        "\n",
        "mean_squared_error = np.sqrt(np.mean(predictionErrorAbs * predictionErrorAbs))\n",
        "print('mean squared error total image: ', mean_squared_error)\n",
        "\n",
        "# slice_nbr = 100\n",
        "slice_nbr = int(inputImage.shape[1]/2) #centre slice\n",
        "view_slices_3d(inputImage, slice_nbr=slice_nbr, vmin=0, vmax=1, title='The Input to the Model (scaled for CNN)')\n",
        "view_slices_3d(predImage, slice_nbr=slice_nbr, vmin=0, vmax=PREDICT_FLAGS['train_normalization'], title='The B1 Prediction (scaled back)')\n",
        "view_slices_3d(gtImage, slice_nbr=slice_nbr, vmin=0, vmax=PREDICT_FLAGS['train_normalization'], title='The measured SA2RAGE B1 map ')\n",
        "view_slices_3d(predictionErrorPercent, slice_nbr=slice_nbr, vmin=-50, vmax=50, title='The relative Error Image', cmap='viridis')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}